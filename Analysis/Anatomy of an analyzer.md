# 分析器解析

不管是内建的还是自定义的分析器，都是包含三个较低级别构建块的包，三个构建块包括：字符过滤器（character filter），分词器（tokenizers），分词过滤器。

内建的分析器将这些构建块预打包进分析器，适用于不同的语言以及文本类型。Elasticsearch也将独立的构建块暴露出来，这样就可以组合起来自定义一个新的分析器。

## 字符过滤器(Character filters)

字符过滤器接受字符流格式的原始文本，通过增加、删除或改变字符来转变文本。比如，使用字符过滤器将印度-阿拉伯数字（٠‎١٢٣٤٥٦٧٨‎٩‎）转变成阿拉伯-拉丁的等价形式，或者跳过HTML元素比如`<b>`。

分析器可能拥有0个或多个字符过滤器，它们按顺序被应用。

## 分词器(Tokenizer)

分词器接受字符流，将其拆分为独立的分词（通常是单独的单词），以分词流的形式输出。比如，`whitespace`分词器在所有空格的地方将文本拆分成分词。它将文本"Quick brown fox!"转变成分词`[Quick, brown, fox!]`。

分词器还负责记录每个分词的顺序或者位置，以及分词所表示的原始单词的开始和结束字符的偏移。

分析器只能有一个分词器。

## 分词过滤器(Token filters)

分词过滤器接受分词流，可以添加、删除、改变分词。比如，`lowercase`分词过滤器将所有的分词都转变为小写，`stop`分词过滤器从分词流中删除常见词（停词）比如`the`，`synonym`（同义词）过滤器将同义词引入分词流。

分词过滤器不允许改变分词的位置或字符偏移。

分析器可能拥有0个或多个分词过滤器，它们按顺序被应用。
